---
- arguments:

#   - torch_threads: 1
#     optim: [
#       # sgd,
#       # adam, adahessian,
#       # adahesscale, adahesscale_sqrt, adahesscale_adamstyle,
#       # adahesscalegn, adahesscalegn_sqrt, adahesscalegn_adamstyle,
#       adaggnmc,
#       ]
#     lr: [.000003, .00001, .00003, .0001, .0003, .001, .003, .01, 1.]
#     eps: [.00001]
#     task: ['Ant', 'Walker2d', 'HalfCheetah', 'Hopper', 'InvertedDoublePendulum']
#     learner: a2c
#     network: fcn_tanh_small
#     n_samples: 2000000
#     exp_name: rl_a2c_5

  - torch_threads: 1
    optim: [
      # sgd_scaled, sgd_scaled_sqrt,
      # adam_scaled, adam_scaled_sqrt, adahessian_scaled,
      # adahesscale_scaled, adahesscale_sqrt_scaled, adahesscale_adamstyle_scaled,
      # adahesscalegn_scaled, adahesscalegn_sqrt_scaled, adahesscalegn_adamstyle_scaled,
      # adaggnmc_scaled,
      adam_hesscale_new,
      # adahessian_hesscale_scaled_new,
      ]
    # lr: [.0003, .001, .003, .01, .03, .1, .3, 1.]
    lr: [.000003, .00001, .00003, .0001, .0003, .001, .003, .01, 1.]
    # delta: [.00000001, .00001, .0001, .001]
    # delta: [.00000001, .00001]
    delta: [.00000001]
    eps: [.00001]
    # task: ['Ant', 'Walker2d', 'HalfCheetah', 'Hopper', 'InvertedDoublePendulum']
    # task: ['Ant', 'Walker2d', 'HalfCheetah', 'Hopper', 'InvertedDoublePendulum', 'InvertedPendulum', 'Swimmer', 'Reacher']
    # n_samples: 2000000
    task: ['Humanoid', 'HumanoidStandup']
    n_samples: 10000000
    learner: a2c
    network: fcn_tanh_small
    exp_name: rl_a2c_5

  script: ../../core/run/rl_run.py
  # admin_args:
  seeds: [0, 9]
  node_preps:
    - ../../node_preps/environment.sh
    - ../../node_preps/rl.sh
  sbatch_args:
    account: def-ashique
    signal: USR1@90
    cpus-per-task: 12
    mem-per-cpu: 2G
    # time: 0-5:58:00
    time: 0-23:58:00
  source_info:
    dir: ../../
    copy: true
    exclude: ['.*', '__pycache__/', '*.egg-info', 'job_files/', 'srun_errors.txt', 'logs/', 'slurm-*.out', '/envhes/', '/backpack/', '/build/', '/cleanrl/', '/SenseAct/', 'generated_cmds/', 'plots/']

  run_type: 'ReinforcementLearningRun'
  description: 'default'


