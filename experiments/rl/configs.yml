---
- arguments:

  - optim: [
      sgd, adam,
      adahesscale, adahesscale_sqrt, adahesscale_adamstyle,
      adahesscalegn, adahesscalegn_sqrt, adahesscalegn_adamstyle,
    ]
    lr: [.000003, .00001, .00003, .0001, .0003, .001, .003, .01]
    task: ['Ant', 'Walker2d', 'HalfCheetah', 'Hopper', 'InvertedDoublePendulum']
    learner: a2c
    network: fcn_tanh_small
    n_samples: 1000000
    exp_name: exp4_Ant5

  # - optim: [
  #     adam_scaled, adam_scaled_sqrt,
  #     adahesscale_scaled, adahesscale_sqrt_scaled, adahesscale_adamstyle_scaled,
  #     adahesscalegn_scaled, adahesscalegn_sqrt_scaled, adahesscalegn_adamstyle_scaled,
  #   ]
  #   lr: [.0003, .001, .003, .01, .03, .1, .3, 1.]
  #   delta: [.00001, .0001, .001]
  #   task: ['Ant', 'Walker2d', 'HalfCheetah', 'Hopper', 'InvertedDoublePendulum']
  #   learner: a2c
  #   network: fcn_tanh_small
  #   n_samples: 1000000
  #   exp_name: exp4_Ant5

  script: ../../core/run/rl_run.py
  # admin_args:
  seeds: [0, 9]
  node_preps:
    - ../../node_preps/environment.sh
  sbatch_args:
    account: rrg-ashique
    signal: USR1@90
    cpus-per-task: 12
    mem-per-cpu: 2G
    time: 0-1:58:00

  run_type: 'ReinforcementLearningRun'
  description: 'default'
