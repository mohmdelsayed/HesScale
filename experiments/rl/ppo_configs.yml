---
- arguments:

  - torch_threads: 1
    # env_id: ['Ant-v2', 'Walker2d-v2', 'HalfCheetah-v2', 'Hopper-v2', 'InvertedDoublePendulum-v2']
    # env_id: ['InvertedPendulum-v2', 'Swimmer-v2', 'Reacher-v2']
    # total_timesteps: 2000000
    env_id: ['Humanoid-v2', 'HumanoidStandup-v2']
    total_timesteps: 10000000
    optim: [
      # sgd,
      # adam, adahessian,
      # adahesscale, adahesscale_sqrt, adahesscale_adamstyle,
      # adahesscalegn, adahesscalegn_sqrt, adahesscalegn_adamstyle,
      adam,
      ]
    learning_rate: [.000003, .00001, .00003, .0001, .0003, .001, .003, .01, 1.]
    eps: [.00001]
    exp_name: rl_ppo_5

  - torch_threads: 1
    # env_id: ['Ant-v2', 'Walker2d-v2', 'HalfCheetah-v2', 'Hopper-v2', 'InvertedDoublePendulum-v2']
    # env_id: ['Ant-v2', 'Walker2d-v2', 'HalfCheetah-v2', 'Hopper-v2', 'InvertedDoublePendulum-v2', 'InvertedPendulum-v2', 'Swimmer-v2', 'Reacher-v2']
    # total_timesteps: 2000000
    env_id: ['Humanoid-v2', 'HumanoidStandup-v2']
    total_timesteps: 10000000
    optim: [
      # sgd_scaled, sgd_scaled_sqrt,
      # adam_scaled, adam_scaled_sqrt, adahessian_scaled,
      # adahesscale_scaled, adahesscale_sqrt_scaled, adahesscale_adamstyle_scaled,
      # adahesscalegn_scaled, adahesscalegn_sqrt_scaled, adahesscalegn_adamstyle_scaled,
      adam_hesscale_new,
      # adahessian_hesscale_scaled_new,
      adahesscale_adamstyle_scaled,
      ]
    # learning_rate: [.0003, .001, .003, .01, .03, .1, .3, 1.]
    learning_rate: [.000003, .00001, .00003, .0001, .0003, .001, .003, .01, 1.]
    # delta: [.00000001, .00001]
    delta: [.00000001]
    eps: [.00001]
    exp_name: rl_ppo_5

  # - torch_threads: 1
  #   # env_id: ['Ant-v2', 'Walker2d-v2', 'HalfCheetah-v2', 'Hopper-v2', 'InvertedDoublePendulum-v2']
  #   env_id: ['Ant-v2', 'Walker2d-v2', 'HalfCheetah-v2', 'Hopper-v2', 'InvertedDoublePendulum-v2', 'InvertedPendulum-v2', 'Swimmer-v2', 'Reacher-v2']
  #   total_timesteps: 2000000
  #   # env_id: ['Humanoid-v2', 'HumanoidStandup-v2']
  #   # total_timesteps: 10000000
  #   optim: [
  #     kfac,
  #     # adam, adahesscale_adamstyle,
  #     # adam_scaled, adahesscale_adamstyle_scaled,
  #     # adam_hesscale_new,
  #     ]
  #   learning_rate: [.000003, .00001, .00003, .0001, .0003, .001, .003, .01, 1.]
  #   kl_clip: [.001, .00000001]
  #   # damping: [.001]
  #   # kl_clip: [.00000001]
  #   # damping: [.00001]
  #   exp_name: rl_ppo_3

#   # 20M-step runs
#   - torch_threads: 1
#     env_id: ['Ant-v2']
#     delta: [.000001, .00001, .0001, .001]
#     optim: [
#       # sgd,
#       # sgd_scaled, sgd_scaled_sqrt,
#       # adam, adahessian,
#       adam_scaled, adam_scaled_sqrt, adahessian_scaled,
#       adahesscale_scaled, adahesscale_sqrt_scaled, adahesscale_adamstyle_scaled,
#       adahesscalegn_scaled, adahesscalegn_sqrt_scaled, adahesscalegn_adamstyle_scaled,
#       ]
#     learning_rate: [.000003, .00001, .00003, .0001, .0003, .001, .003, .01, .03, .1, .3, 1.]
#     eps: [.00001]
#     total_timesteps: 20000000
#     exp_name: rl_ppo_4

  script: ../../core/run/ppo_continuous_action.py
  # script: ../../core/run/kfac_ppo_continuous_action.py
  # admin_args:
  seeds: [0, 9]
  node_preps:
    - ../../node_preps/environment.sh
    - ../../node_preps/rl.sh
  sbatch_args:
    account: rrg-ashique
    signal: USR1@90
    cpus-per-task: 12
    mem-per-cpu: 512M
    # time: 0-5:58:00
    time: 0-23:58:00
    # time: 0-34:58:00
  source_info:
    dir: ../../
    copy: true
    exclude: ['.*', '__pycache__/', '*.egg-info', 'job_files/', 'srun_errors.txt', 'logs/', 'slurm-*.out', '/envhes/', '/backpack/', '/build/', '/cleanrl/', '/SenseAct/', 'generated_cmds/', 'plots/']

  run_type: 'ReinforcementLearningRun'
  description: 'default'




