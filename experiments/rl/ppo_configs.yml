---
- arguments:

  # - torch_threads: 1
  #   env_id: ['Ant-v2']
  #   optim: [adahesscale_adamstyle_scaled]
  #   learning_rate: [.000003]
  #   total_timesteps: 10000
  #   exp_name: rl_ppo_0

#   - torch_threads: 1
#     env_id: ['Ant-v2', 'Walker2d-v2', 'HalfCheetah-v2', 'Hopper-v2', 'InvertedDoublePendulum-v2']
#     optim: [
#       sgd, adam,
#       adahesscale, adahesscale_sqrt, adahesscale_adamstyle,
#       adahesscalegn, adahesscalegn_sqrt, adahesscalegn_adamstyle,
#       ]
#     learning_rate: [.000003, .00001, .00003, .0001, .0003, .001, .003, .01]
#     total_timesteps: 1000000
#     exp_name: rl_ppo_1

  - torch_threads: 1
    env_id: ['Ant-v2', 'Walker2d-v2', 'HalfCheetah-v2', 'Hopper-v2', 'InvertedDoublePendulum-v2']
    optim: [
      adam_scaled, adam_scaled_sqrt,
      adahesscale_scaled, adahesscale_sqrt_scaled, adahesscale_adamstyle_scaled,
      adahesscalegn_scaled, adahesscalegn_sqrt_scaled, adahesscalegn_adamstyle_scaled,
      ]
    learning_rate: [.0003, .001, .003, .01, .03, .1, .3, 1.]
    delta: [.00001, .0001, .001]
    total_timesteps: 1000000
    exp_name: rl_ppo_1

  script: ../../core/run/ppo_continuous_action.py
  # admin_args:
  seeds: [0, 9]
  node_preps:
    - ../../node_preps/environment.sh
    - ../../node_preps/rl.sh
  sbatch_args:
    account: rrg-ashique
    signal: USR1@90
    cpus-per-task: 12
    mem-per-cpu: 512M
    time: 0-1:58:00
  source_info:
    dir: ../../
    copy: true
    exclude: ['.*', '__pycache__/', '*.egg-info', 'job_files/', 'srun_errors.txt', 'logs/', 'slurm-*.out', '/envhes/', '/backpack/', '/build/', '/cleanrl/', 'generated_cmds/', 'plots/']

  run_type: 'ReinforcementLearningRun'
  description: 'default'
