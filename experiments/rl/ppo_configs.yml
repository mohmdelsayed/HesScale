---
- arguments:

#   - torch_threads: 1
#     env_id: ['Ant-v2', 'Walker2d-v2', 'HalfCheetah-v2', 'Hopper-v2', 'InvertedDoublePendulum-v2']
#     optim: [
#       # sgd,
#       # adam, adahessian,
#       # adahesscale, adahesscale_sqrt, adahesscale_adamstyle,
#       # adahesscalegn, adahesscalegn_sqrt, adahesscalegn_adamstyle,
#       adaggnmc,
#       ]
#     learning_rate: [.000003, .00001, .00003, .0001, .0003, .001, .003, .01, 1.]
#     eps: [.00001]
#     total_timesteps: 2000000
#     exp_name: rl_ppo_3

  # - torch_threads: 1
  #   env_id: ['Ant-v2', 'Walker2d-v2', 'HalfCheetah-v2', 'Hopper-v2', 'InvertedDoublePendulum-v2']
  #   optim: [
  #     sgd_scaled, sgd_scaled_sqrt,
  #     # adam_scaled,
  #     # adam_scaled_sqrt, adahessian_scaled,
  #     # adahesscale_scaled, adahesscale_sqrt_scaled, adahesscale_adamstyle_scaled,
  #     # adahesscalegn_scaled, adahesscalegn_sqrt_scaled, adahesscalegn_adamstyle_scaled,
  #     ]
  #   # learning_rate: [.0003, .001, .003, .01, .03, .1, .3, 1.]
  #   learning_rate: [.000003, .00001, .00003, .0001, .0003, .001, .003, .01, 1.]
  #   delta: [.00000001, .00001, .0001, .001]
  #   # eps: [.00001]
  #   total_timesteps: 2000000
  #   exp_name: rl_ppo_3

  # 20M-step runs
  - torch_threads: 1
    env_id: ['Ant-v2']
    optim: [
      # adam, adahesscale_adamstyle,
      adam_scaled, adahesscale_adamstyle_scaled,
      ]
    learning_rate: [.000003, .00001, .00003, .0001, .0003, .001, .003, .01, 1.]
    delta: [.00000001]
    eps: [.00001]
    total_timesteps: 20000000
    exp_name: rl_ppo_4

  script: ../../core/run/ppo_continuous_action.py
  # admin_args:
  seeds: [0, 9]
  node_preps:
    - ../../node_preps/environment.sh
    - ../../node_preps/rl.sh
  sbatch_args:
    account: def-ashique
    signal: USR1@90
    cpus-per-task: 12
    mem-per-cpu: 512M
    # time: 0-2:58:00
    time: 0-71:58:00
  source_info:
    dir: ../../
    copy: true
    exclude: ['.*', '__pycache__/', '*.egg-info', 'job_files/', 'srun_errors.txt', 'logs/', 'slurm-*.out', '/envhes/', '/backpack/', '/build/', '/cleanrl/', '/SenseAct/', 'generated_cmds/', 'plots/']

  run_type: 'ReinforcementLearningRun'
  description: 'default'
